{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdf6c18",
   "metadata": {},
   "source": [
    "# Predicting heart disease using machine learning \n",
    "\n",
    "This notebook looks into using various `Python-based machine learning` and `data science libraries` in an attempt to build a machine learning model capable of predicting whether or not someone has heart disease based on their medical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badcc6c8",
   "metadata": {},
   "source": [
    "We are going to take the following approach\n",
    "1. Problem definition\n",
    "2. Data\n",
    "3. Evaluation\n",
    "4. Features\n",
    "5. Modelling\n",
    "6. Experimentation\n",
    "\n",
    "\n",
    "## 1. Problem Definition\n",
    "\n",
    "In a statement,\n",
    "> Given clinical parameters about a patient, can we predict whether or not they have heart disease?\n",
    "\n",
    "## 2. Data\n",
    "\n",
    "The original data if from the Cleveland data from the UCI machine Learning Repository. https://archive.ics.uci.edu/ml/datasets/heart+disease\n",
    "\n",
    "There is also a version on Kaggle. https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f2e6f",
   "metadata": {},
   "source": [
    "## 3. Evaluation\n",
    "\n",
    "> If we can reach 95% accuracy at predicting whether or not a patient has heart disease during the proof of concept, we will pursue the project.\n",
    "\n",
    "## 4. Features\n",
    "\n",
    "This where you get different information about each of the features in your data\n",
    "\n",
    "**Create data dictionary**\n",
    "\n",
    "1. age\n",
    ">age in years\n",
    "\n",
    "2. sex\n",
    ">(1 = male; 0 = female)\n",
    "\n",
    "3. cp\n",
    ">chest pain type\n",
    "\n",
    "4. trestbps\n",
    ">resting blood pressure (in mm Hg on admission to the hospital)\n",
    "\n",
    "5. chol\n",
    ">serum cholestoral in mg/dl\n",
    "\n",
    "6. fbs\n",
    ">(fasting blood sugar &gt; 120 mg/dl) (1 = true; 0 = false)\n",
    "\n",
    "7. restecg\n",
    ">resting electrocardiographic results\n",
    "\n",
    "8. thalach\n",
    ">maximum heart rate achieved\n",
    "\n",
    "9. exang\n",
    ">exercise induced angina (1 = yes; 0 = no)\n",
    "\n",
    "10. oldpeak\n",
    ">ST depression induced by exercise relative to rest\n",
    "\n",
    "11. slope\n",
    ">the slope of the peak exercise ST segment\n",
    "\n",
    "12. ca\n",
    ">number of major vessels (0-3) colored by flourosopy\n",
    "\n",
    "13. thal\n",
    ">1 = normal; 2 = fixed defect; 3 = reversable defect\n",
    "\n",
    "14. target\n",
    ">1 or 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e7f861",
   "metadata": {},
   "source": [
    "## Preparing the tools\n",
    "\n",
    "We are going to use Pandas, Numpy and Matplotlib for data analysis and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4579781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the tools we need\n",
    "\n",
    "# Regular EDA and plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import dill\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# So that our plot will appear inside the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "\n",
    "# Models from scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Model Evaluations\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score,RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,plot_roc_curve,RocCurveDisplay\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0678adc2",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"D:\\\\OneDrive\\\\Documents\\\\Personal Project Portfolio\\\\heart-diesease-project_Classification\\\\app\\\\data\\\\heart-disease.csv\")\n",
    "df.shape # (Rows, Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4568ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eeb0e5",
   "metadata": {},
   "source": [
    "# Data Exploratory Analysis (EDA)\n",
    "\n",
    "The goal here is to find our more about the data and become a subject matter expert on the dataset you are working with.\n",
    "\n",
    "1. What questions are you trying to solve\n",
    "2. What kind of data do you have and how do we treat different types?\n",
    "3. What is missing from the data and how do you deal with it\n",
    "4. Where are the outliers and why should you care about them?\n",
    "5. How can you add, change or remove features to get more out of your data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ceb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad177f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad19cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target.value_counts() # method 1 of referencing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aae1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts() # method 2 of referencing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target.value_counts().plot(kind='bar',color=['black','gray'],\n",
    "                              ylabel='counts', xlabel='target', title='Target Value Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c1c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387978e",
   "metadata": {},
   "source": [
    "### Heart Disease Frequency according to Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9965b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cfbe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.value_counts().plot(kind='bar',color=['black','gray']\n",
    "                           )\n",
    "plt.legend(['1:Male', '0:Female']);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe610cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare target column with the sex column\n",
    "pd.crosstab(df.target,df.sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a plot of the crosstab\n",
    "pd.crosstab(df.target,df.sex).plot(kind='bar',\n",
    "                                  figsize=(10,6),\n",
    "                                  color=['black','gray']);\n",
    "\n",
    "plt.title('Heart Disease Frequency for Sex')\n",
    "plt.xlabel('0= No Disease, 1 = Disease')\n",
    "plt.ylabel ('Number of People')\n",
    "plt.legend(['Female','Male']);\n",
    "plt.xticks(rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34377b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.thalach.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4111171f",
   "metadata": {},
   "source": [
    "#### Age Vs Max Heart Rate for Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26efcf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another figure\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# scatter with positive example\n",
    "plt.scatter(df.age[df.target==1],\n",
    "            df.thalach[df.target==1],\n",
    "            color=['Salmon'])\n",
    "\n",
    "# scatter with negative example\n",
    "plt.scatter(df.age[df.target==0],\n",
    "            df.thalach[df.target==0],\n",
    "            color='black');\n",
    "\n",
    "#Add some helpful info\n",
    "\n",
    "plt.title('Heart Disease in function of Age and Max Heart Disease')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Max Heart Rate')\n",
    "plt.legend(['disease','No Disease']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb426881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the Age column (Spread of the data)\n",
    "df.age.plot.hist(color='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b672cb",
   "metadata": {},
   "source": [
    "## Compare the Chest Pain Type to Target\n",
    "Heart disease frequency per chest pain type\n",
    "\n",
    "cp: chest pain type\n",
    "* Value 1: typical angina\n",
    "* Value 2: atypical angina\n",
    "* Value 3: non-anginal pain\n",
    "* Value 4: asymptomatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.cp,df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2259a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the crosstab more visual\n",
    "\n",
    "pd.crosstab(df.cp,df.target).plot(kind='bar',color=['black','gray'],\n",
    "                                 figsize=(10,6))\n",
    "\n",
    "# Add some communication\n",
    "plt.title('Heart Diseease and Chest Pain Type')\n",
    "plt.xlabel('Type of Chest pain :0= typical angina, 1= atypical angina, 2= non-anginal pain, 3 = asymptomatic')\n",
    "plt.ylabel('Number of people')\n",
    "plt.legend(['No Disease','Disease']);\n",
    "plt.xticks(rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6d9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,6, figsize=(17,17),sharey=True)\n",
    "\n",
    "sns.histplot(df, x='age',kde=True, ax=axs[0,0] )\n",
    "sns.histplot(df, x='sex',kde=True, ax=axs[0,1] )\n",
    "sns.histplot(df, x='cp',kde=True, ax=axs[0,2] )\n",
    "sns.histplot(df, x='trestbps',kde=True, ax=axs[0,3] )\n",
    "sns.histplot(df, x='chol',kde=True, ax=axs[0,4] )\n",
    "sns.histplot(df, x='fbs',kde=True, ax=axs[0,5] )\n",
    "sns.histplot(df, x='restecg',kde=True, ax=axs[1,0] )\n",
    "sns.histplot(df, x='thalach',kde=True, ax=axs[1,1] )\n",
    "sns.histplot(df, x='exang',kde=True, ax=axs[1,2] )\n",
    "sns.histplot(df, x='oldpeak',kde=True, ax=axs[1,3] )\n",
    "sns.histplot(df, x='slope',kde=True, ax=axs[1,4] )\n",
    "sns.histplot(df, x='ca',kde=True, ax=axs[1,5] )\n",
    "sns.histplot(df, x='thal',kde=True, ax=axs[2,0] )\n",
    "sns.histplot(df, x='target',kde=True, ax=axs[2,1] );\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a correlation matrix of all the features\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d36390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make our correlation matrix a little better\n",
    "corr_matrix=df.corr()\n",
    "fig,ax =plt.subplots(figsize=(15,10))\n",
    "\n",
    "ax =sns.heatmap(corr_matrix,\n",
    "               annot=True,\n",
    "               linewidth=0.5,\n",
    "               fmt='.2f',\n",
    "               cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2088c47",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "X= df.drop('target',axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "np.random.seed(42)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b0dfa2",
   "metadata": {},
   "source": [
    "Now that we have the data into training and test sets, it's time to build a machine learning model\n",
    "\n",
    "We will train it (find the patterns) on the training set\n",
    "And we will test it (use the patterns) on the test set\n",
    "\n",
    "We are going to try out 3 different machine learning models\n",
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbours Classifier\n",
    "3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd769085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put models in a dictionary\n",
    "models = {'Logistic Regression': LogisticRegression(),\n",
    "          'KNN':KNeighborsClassifier(),\n",
    "          'Randon Forest':RandomForestClassifier(),\n",
    "          'SVM': SVC(),\n",
    "          'XGB': XGBClassifier(), \n",
    "          'LightGBM': lgb.LGBMClassifier()}\n",
    "\n",
    "# Create a function to fit and score models\n",
    "def fit_and_score (models,X_Train,X_test,y_train,y_test):\n",
    "    '''\n",
    "    Fits and evaluates given machine learning models\n",
    "    models: a dict of differeny Scikit-Learn machine learning models\n",
    "    X_train: training data (no labels)\n",
    "    X_test: test data (no labels)\n",
    "    y_train: training labels\n",
    "    y_test: test labels\n",
    "\n",
    "    '''\n",
    "    # set random seed\n",
    "    np.random.seed(42)\n",
    "\n",
    "    #make a dictionary to keep model scores\n",
    "    model_scores={}\n",
    "\n",
    "    # Loop through the models'\n",
    "    for name,model in models.items():\n",
    "        #Fit the model to the data\n",
    "        model.fit(X_train,y_train)\n",
    "        #Evaluate the model and append the score to model_score\n",
    "        model_scores[name]=model.score(X_test,y_test)\n",
    "    return model_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = fit_and_score(models=models,\n",
    "                             X_Train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_train=y_train,\n",
    "                            y_test=y_test)\n",
    "\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea6bf",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d86c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare=pd.DataFrame(model_scores,index=['accuracy'])\n",
    "model_compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb61b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare.T.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d106c11",
   "metadata": {},
   "source": [
    "Now we have got a baseline model and know a model's first predictions aren't always what we should base our next steps off.\n",
    "What should i do?\n",
    "\n",
    "let's look at the following:\n",
    "* Hyperparameter tuning (*all types of models*)\n",
    "* Feature importance (*all types of models*)\n",
    "* Confusion matrix (*classification models only*)\n",
    "* Cross-validation (*classification models only*???)\n",
    "* Precision (*classification models only*)\n",
    "* Recall (*classification models only*)\n",
    "* F1 Score (*classification models only*)\n",
    "* Classification report (*classification models only*)\n",
    "* ROC curve (*classification models only*)\n",
    "* Area under the curve (AUC) (*classification models only*)\n",
    "\n",
    "## Hyperparameter tuning (by hand)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47042178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's tune KNN\n",
    "train_scores =[]\n",
    "test_scores =[]\n",
    "\n",
    "# Create a list if different values for n_neighbors\n",
    "neighbors = range(1,21)\n",
    "\n",
    "#Setup KNN instance \n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# loop through different n_neighbors\n",
    "for i in neighbors:\n",
    "    knn.set_params(n_neighbors=i)\n",
    "    \n",
    "    #fit the algorithm\n",
    "    knn.fit(X_train,y_train)\n",
    "    \n",
    "    #update the training scores list\n",
    "    train_scores.append(knn.score(X_train,y_train))\n",
    "    \n",
    "    #update the test scores list\n",
    "    test_scores.append(knn.score(X_test,y_test))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5554ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8337fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(neighbors,train_scores,label='train score')\n",
    "plt.plot(neighbors,test_scores,label='test score');\n",
    "\n",
    "\n",
    "#Add some communications\n",
    "plt.title(\"KNN n-neighbors tuning\")\n",
    "plt.xlabel('Number of n-neighbors')\n",
    "plt.xticks(np.arange(1,21,1))\n",
    "plt.ylabel('score')\n",
    "plt.legend(['train score','test score'])\n",
    "\n",
    "print (f'Maximum KNN score on the test data: {max(test_scores)*100:.2f}%');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e54335",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning (by RandomizedSearchCV )\n",
    "\n",
    "We are going to tune:\n",
    "* LogisticRegression()\n",
    "* RandomForestClassifier()\n",
    ".......RandomizedSearchCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86cbb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hyperparameter grid for LogisticRegression()\n",
    "log_reg_grid = {\"C\":np.logspace(-4,4,20),\n",
    "               'solver':['liblinear']}\n",
    "\n",
    "# Create a hyperparameter grid for RandomForestClassifier()\n",
    "rf_grid= {'n_estimators':np.arange(10,1000,50),\n",
    "         'max_depth':[None,3,5,10],\n",
    "         'min_samples_split':np.arange(2,20,2),\n",
    "         'min_samples_leaf':np.arange(1,20,2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec493daf",
   "metadata": {},
   "source": [
    "Now we have hyperparameter grids setup for each of our models, lets tune them using RandomizedSearchCV... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b6d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune LogisticRegression\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# setup random hyperparameter search for LogisticRegression\n",
    "rs_log_reg =RandomizedSearchCV(LogisticRegression(),\n",
    "                              param_distributions=log_reg_grid,\n",
    "                              cv=5,\n",
    "                              n_iter=20,\n",
    "                              verbose=True)\n",
    "\n",
    "# Fit random hyperparameter search model for LogisticRegression\n",
    "rs_log_reg.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3778b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_log_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbcda8e",
   "metadata": {},
   "source": [
    "Now we have tuned LogisticRegression(), let's do the same for RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8983a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# setup random hyperparameter search for RandomForestClassifier\n",
    "rf =RandomizedSearchCV(RandomForestClassifier(),\n",
    "                              param_distributions=rf_grid,\n",
    "                              cv=5,\n",
    "                              n_iter=20,\n",
    "                              verbose=True)\n",
    "\n",
    "# Fit random hyperparameter search model for RandomForestClassifier\n",
    "rf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best hyperparameters\n",
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the randomized search RandomForestClassifier model\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ccc0e",
   "metadata": {},
   "source": [
    "## Tuning hyperparameter (Use the GridSearchCV for the LogisticRegression() model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6403d19",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "Since our logisticRegression model provides the best score so far, we'll try and improve them again using GridSearchCV..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed04700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different parameters for our LogisticRegression model\n",
    "log_reg_grid= {'C': np.logspace(-4,4,100),\n",
    "              'solver':['liblinear']}\n",
    "\n",
    "#Setup grid hyperparameter search for LogisticRegression\n",
    "gs_log_reg =GridSearchCV(LogisticRegression(),\n",
    "                        param_grid=log_reg_grid,\n",
    "                        cv=5,\n",
    "                        verbose=True)\n",
    "\n",
    "#Fit grid hyperparameter search model\n",
    "gs_log_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e2949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the grid search LogisticRegression() model\n",
    "gs_log_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1a8944",
   "metadata": {},
   "source": [
    "## Evaluating our tuned machine learning classifier, beyond accuracy\n",
    "\n",
    "* ROC curve and AUC\n",
    "* Confusion matrix\n",
    "* Classification report\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score\n",
    "\n",
    "...and it would be great if cross-validation was used where possible.\n",
    "\n",
    "To make comparisons and evaluate our trained model, first we need to make predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99367ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with tuned model\n",
    "y_preds =gs_log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31be5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2ad61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot the ROC curve and calculate the AUC metric\n",
    "plot_roc_curve(gs_log_reg,X_test,y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7be51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the latest method for ROC Curve\n",
    "#import the required function\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "\n",
    "RocCurveDisplay.from_estimator(gs_log_reg, X_test, y_test);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a40ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_predictions(y_test,y_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175cbeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print (confusion_matrix(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4015531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise using seaborn\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "def plot_conf_mat(y_test,y_preds):\n",
    "    '''\n",
    "    Plot a nice looking confusion matrix using seaborn's heatmap()\n",
    "    '''\n",
    "    fig,ax =plt.subplots(figsize=(3,3))\n",
    "    ax =sns.heatmap(confusion_matrix(y_test,y_preds),\n",
    "                   annot=True,\n",
    "                   cbar=False)\n",
    "    plt.xlabel('True Label')\n",
    "    plt.ylabel('Predicted Label')\n",
    "    \n",
    "plot_conf_mat(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcec6310",
   "metadata": {},
   "source": [
    "Now we've got the ROC curve, an AUC metric, a confusion matrix, let's get a classification report as well as cross-validated precision, recall and f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb87af4",
   "metadata": {},
   "source": [
    "### Calculate evaluation metrics (precision ,recall and f1-score) using cross-validation\n",
    "\n",
    "We are going to calculate precision, recall and f1-score of our model using cross-validation and to do so we will be using cross_val_score().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a956287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the best hyperparameters \n",
    "gs_log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a091632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier with best parameters\n",
    "clf =LogisticRegression(C=0.20565123083486536,solver ='liblinear')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validated accuracy\n",
    "cv_acc=cross_val_score(clf,\n",
    "                       X,\n",
    "                       y,\n",
    "                       cv=5,\n",
    "                       scoring ='accuracy')\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e565ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_acc=np.mean(cv_acc)\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a922d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validated precision\n",
    "cv_precision=cross_val_score(clf,\n",
    "                       X,\n",
    "                       y,\n",
    "                       cv=5,\n",
    "                       scoring ='precision')\n",
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_precision=np.mean(cv_precision)\n",
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validated recall\n",
    "cv_recall =cross_val_score(clf,\n",
    "                       X,\n",
    "                       y,\n",
    "                       cv=5,\n",
    "                       scoring ='recall')\n",
    "cv_recall=np.mean(cv_recall)\n",
    "cv_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f7aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validated f1-score\n",
    "cv_f1 =cross_val_score(clf,\n",
    "                       X,\n",
    "                       y,\n",
    "                       cv=5,\n",
    "                       scoring ='f1')\n",
    "cv_f1=np.mean(cv_f1)\n",
    "cv_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01803c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the cross-validated metrics\n",
    "cv_metrics =pd.DataFrame({'Accuracy':cv_acc,\n",
    "                        'Precision':cv_precision,\n",
    "                        'Recall':cv_recall,\n",
    "                        'F1':cv_f1},index =[0])\n",
    "cv_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab04ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_metrics.T.plot(kind='bar',color='black',title='Cross-validated classification metrics',legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc2d7e4",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Feature importance is another way of asking, \"which features contributed most to the outcomes of the model and how did they contribute?\"\n",
    "\n",
    "Finding feature importance is different for each machine learning model.One way to find feature importance is to search for ('MODEL NAME') feature importance\n",
    "\n",
    "Let's find the feature importance for our LogisticRegression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8700a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an instance of LogisticRegression\n",
    "\n",
    "clf= LogisticRegression(C=0.20565123083486536,solver ='liblinear')\n",
    "\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check coef_\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2aef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match coef's of features to columns\n",
    "feature_dict=dict(zip(df.columns,list(clf.coef_[0])))\n",
    "feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102e184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise feature importances\n",
    "feature_df =pd.DataFrame(feature_dict,index=[0])\n",
    "feature_df.T.plot.barh(title='Feature Imporatnce',legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9581890",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['sex'],df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748ab48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df['slope'],df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4e337",
   "metadata": {},
   "source": [
    "slope-the slope of the peak exercise ST segment\n",
    "* 0: Upsloping: better heart rate with exercise (uncommon)\n",
    "* 1: Flatsloping: minimal change (typical healthy heart)\n",
    "* 2: Downsloping signs of unhealthy heart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248053f2",
   "metadata": {},
   "source": [
    "## 6. Experimentation\n",
    "\n",
    "If you haven't hit your evaluation metric target yet......ask yourself...\n",
    "\n",
    "* Could you collect more data?\n",
    "* Could you try a better model? Like CatBoost or XGBoost?\n",
    "* Could you improve the current models ? (beyond what is done so far)\n",
    "\n",
    "If model is good enough (you have hit your evaluation metric) how would you export it and share it with others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try XGBoostm lightGBM and SVM clasifier\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n",
    "# !pip install SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688caf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add helper function with hyperparameter tuning with GridSearch CV\n",
    "def evaluate_models(X_train, y_train, X_test, y_test, models, param):\n",
    "    try:\n",
    "        \"\"\"\n",
    "        This method fits and score the models provided while doing a gridsearch cross\n",
    "        validation using the parameter grid provided\n",
    "        \n",
    "        input: X-train - Training data input features\n",
    "             y_train - Training data label \n",
    "             X_test - Test data input features\n",
    "             y_test - Test data labels\n",
    "             models - ML model to experiment with\n",
    "             param :dict - parameter settings to try as values.\n",
    "             \n",
    "        Returns: a dictionary of the a key values pair of model and score\n",
    "        \"\"\" \n",
    "                \n",
    "        report = {}\n",
    "\n",
    "        for i in range(len(list(models))):\n",
    "            model = list(models.values())[i]\n",
    "            para=param[list(models.keys())[i]]\n",
    "\n",
    "            gs = GridSearchCV(model,para,cv=3, verbose=3)\n",
    "            gs.fit(X_train,y_train)\n",
    "\n",
    "            model.set_params(**gs.best_params_)\n",
    "            model.fit(X_train,y_train)\n",
    "\n",
    "            test_model_score = model.score(X_test, y_test)\n",
    "\n",
    "            report[list(models.keys())[i]] = test_model_score\n",
    "        return report\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file_obj:\n",
    "            return dill.load(file_obj)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise CustomException(e, sys)\n",
    "        \n",
    "        \n",
    "def save_object(file_path, obj):\n",
    "    with open(file_path, 'wb') as file_obj:\n",
    "        dill.dump(obj, file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f702d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the fit_score_best_model helper function\n",
    "\n",
    "def fit_and_score_best_model(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Fits and evaluates models passed to it.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    models : Dictionary of machine learning models\n",
    "    X_train : training data (without labels)\n",
    "    X_test : test data (without labels)\n",
    "    y_train : training labels\n",
    "    y_test : test labels\n",
    "    \n",
    "    Returns:\n",
    "    -----------\n",
    "    The best performing model out of the model passed to it\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Set random seed\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Create the parameter grid\n",
    "    params = {\n",
    "    'Logistic Regression': {\n",
    "        'penalty': ['l2'],  # Removing 'None', 'l1', 'elasticnet'\n",
    "        'dual': [False],    # Keeping only False\n",
    "        'solver': ['lbfgs', 'liblinear']  # Most common solvers\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],  # Reduced range\n",
    "        'kernel': ['linear', 'rbf'],  # Most common kernels\n",
    "        'degree': [3],  # Commonly used degree for polynomial kernel\n",
    "        'gamma': ['scale']  # Default value\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'criterion': ['gini'],  # Keeping only 'gini'\n",
    "        'max_features': ['sqrt'],  # Common practice\n",
    "        'n_estimators': [32, 128],  # Reduced range\n",
    "        'max_leaf_nodes': [None],  # Default value\n",
    "        'bootstrap': [True],  # Common practice\n",
    "        'n_jobs': [1],  # Using single core to avoid memory issues\n",
    "        'max_samples': [None],  # Default value\n",
    "        'min_samples_split': [2, 10],  # Reduced range\n",
    "        'min_samples_leaf': [1, 5]  # Reduced range\n",
    "    },\n",
    "    'XGB': {\n",
    "        'learning_rate': [0.01, 0.1],  # Reduced range\n",
    "        'max_depth': [6, 8],  # Commonly used depths\n",
    "        'gamma': [2, 9],  # Reduced range\n",
    "        'sampling_method': ['uniform'],  # Default value\n",
    "        'grow_policy': ['depthwise'],  # Common practice\n",
    "        'n_estimators': [32, 128]  # Reduced range\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'boosting_type': ['gbdt'],  # Common practice\n",
    "        'max_depth': [-1, 2],  # Reduced range\n",
    "        'learning_rate': [0.01, 0.1],  # Reduced range\n",
    "        'n_estimators': [100, 200],  # Reduced range\n",
    "        'num_leaves': [31, 50]  # Reduced range\n",
    "    }\n",
    "}\n",
    "\n",
    "               \n",
    "    # Evaluate the model and append its score to model_report\n",
    "    model_report:dict=evaluate_models(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,\n",
    "                                                models=models, param=params)\n",
    "        \n",
    "    # To get best model score from dict\n",
    "    best_model_score = max(sorted(model_report.values()))\n",
    "        \n",
    "    # To get best model name from dict\n",
    "    best_model_name = list(model_report.keys())[\n",
    "                list(model_report.values()).index(best_model_score)\n",
    "            ]\n",
    "    best_model = models[best_model_name]\n",
    "\n",
    "    if best_model_score < 0.6:\n",
    "        print(\"No best model found\")\n",
    "\n",
    "    save_object(\n",
    "                file_path=\"D:\\\\OneDrive\\\\Documents\\\\Personal Project Portfolio\\\\\"\n",
    "                \"heart-diesease-project_Classification\\\\app\\\\artifacts\\\\best_model\\\\model.pkl\",\n",
    "                obj=best_model\n",
    "            )\n",
    "\n",
    "    return print(f'Best Model: {best_model}, Score: {best_model_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc138a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put models in a dictionary\n",
    "models = {'Logistic Regression':LogisticRegression(),'SVM': SVC(),'Random Forest': RandomForestClassifier(),\n",
    "           'XGB': XGBClassifier(), 'LightGBM': lgb.LGBMClassifier() }\n",
    "\n",
    "best_model = fit_and_score_best_model(models, X_train=X_train, X_test=X_test,\n",
    "                                      y_train=y_train, y_test=y_test)\n",
    "\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa5ff17",
   "metadata": {},
   "source": [
    "## Add Data Transformation Step\n",
    "We would standadise the features since few of the features were skewed (e.g oldpeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a36d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "imputer = SimpleImputer()\n",
    "preprocessor= Pipeline(steps=[\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('imputer', imputer)\n",
    "                    ]\n",
    "                    )\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# save the transformer\n",
    "\n",
    "save_object('artifacts/preprocessor.pkl', preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb37ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom the test data\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b4ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
